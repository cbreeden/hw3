\subsection{Overview}\label{overview}

Let

\[
\xi_1 = (-1, 1, 0) \ \text{and}\ \xi_2 = (0, -1, 1),
\]

and let \(X^\theta_n\) be a discrete time Markov chain on
\(\mathbb{Z}^3_{\geq 0}\) with the following transition probabilities:

\begin{align}
p_{\vec x, \vec x + \xi_1} &= \frac{\theta xy}{\theta xy + y} \\
p_{\vec x, \vec x + \xi_2} &= 1 - p_1(x,y,z),
\end{align}

Assume that \(X^\theta_0 = (100, 5, 0)\) and \(\theta = 0.05\). Let
\(f(X^\theta) = \left(X^\theta_1\right)_{100}\); that is the first
component of the process after 100 steps. We estimate
\(\frac{d}{d\theta} E\left[f(X^\theta)\right]\) using a number of
different techniques.

\subsection{Finite Difference Method}\label{finite-difference-method}

In this problem, we employ a centered finite difference method, using an
estimator

\[
\hat \mu^{\theta, h}_k
      = \frac{f(X^{\theta + h/2}_k) - f(X^{\theta - h/2}_k)}{h}.
\]

In an attempt to reduce the variance, we employ the common random
variables technique; in which we will use the same sequence of uniform
random variables when generating relizations \(X^{\theta + h/2}_k\) and
\(X^{\theta - h/2}_k\).

For the finite difference method we employed the niave algorithm. That
is, for a given value \(h\), we sample the random variable:

\[
Y^{\theta,h} := \frac{f(X^{\theta + h}) - f(X^{\theta})}{h}.
\]

Here we estimated the expected value
\(\hat Y^{\theta,h} = \frac{1}{n} \sum^n Y^{\theta,h}_k\), and the
sample variance \(\sqrt{\sigma}\). We \emph{did not}, however, use

\[
Y^{\theta, h} := h^2 \sum^{h^{-2}} \frac{f(X^{\theta + h}) - f(X^{\theta})}{h}
\]

for our estimator. During our trials, we did, and the sample variance
remained roughly constant throughout different choices of \(h\). We
decided not to use these estimators for our table to illustrate the
additional work required when estimating for small \(h\). We took
100,000 samples.

\begin{longtable}[]{@{}crcc@{}}
\toprule
h & \(\hat Y^{\theta, h}\) & \(\sigma^2\) & Confidence\tabularnewline
\midrule
\endhead
0.01 & -268.59 & 236102.86 & 3.01\tabularnewline
0.005 & -286.76 & 969545.56 & 6.10\tabularnewline
0.001 & -290.61 & 24351035.83 & 30.59\tabularnewline
0.0005 & -349.46 & 97367597.71 & 61.16\tabularnewline
\bottomrule
\end{longtable}

\subsection{Likelihood Ratio Method}\label{likelihood-ratio-method}

For likelihood ratio method, we took \(n = 100,000\) samples.

\begin{longtable}[]{@{}ccc@{}}
\toprule
\(\hat Y^{\theta}\) & \(\sigma^2\) & Confidence\tabularnewline
\midrule
\endhead
-331.29 & 5640541.81 & 46.55\tabularnewline
\bottomrule
\end{longtable}

While emplying a control variate with the weight function obtained using
the Likelihood Ratio method, we had a dramatic reduction in variance.

\begin{longtable}[]{@{}ccc@{}}
\toprule
\(\hat Y^\theta\) & \(\sigma^2\) & Confidence\tabularnewline
\midrule
\endhead
-302.56 & 190379.28 & 8.55\tabularnewline
\bottomrule
\end{longtable}
